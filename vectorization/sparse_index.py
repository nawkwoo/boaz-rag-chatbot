# sparse_index.py
import os
import json
from dotenv import load_dotenv
from pinecone_text.sparse import BM25Encoder
from pinecone import Pinecone, ServerlessSpec, Vector
from config import DATA_PATH, SPARSE_INDEX_NAME

load_dotenv()

def load_texts_from_jsonl(folder_path: str):
    texts = []
    metadatas = []
    for fname in os.listdir(folder_path):
        if not fname.endswith(".jsonl"):
            continue
        with open(os.path.join(folder_path, fname), encoding="utf-8") as f:
            for line in f:
                record = json.loads(line)
                texts.append(record["text"])
                metadatas.append(record["metadata"])
    return texts, metadatas

# âœ… ê²€ìƒ‰ ëª¨ë“ˆì—ì„œ ì‚¬ìš©í•  BM25Encoderë¥¼ ì „ì—­ìœ¼ë¡œ ì´ˆê¸°í™” ë° í•™ìŠµ
texts_for_search, _ = load_texts_from_jsonl(DATA_PATH)
bm25_encoder = BM25Encoder()
bm25_encoder.fit(texts_for_search)

def truncate_sparse_vector(sv, k=800):
    # âœ… ë¹ˆ ë²¡í„°ëŠ” ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜ (sparse vector ê·œì¹™)
    if not sv or "indices" not in sv or len(sv["indices"]) == 0:
        return {"indices": [], "values": []}  # ë¹ˆ sparse vector

    if len(sv["indices"]) <= k:
        return sv

    topk = sorted(
        zip(sv["indices"], sv["values"]),
        key=lambda x: abs(x[1]),
        reverse=True
    )[:k]

    return {
        "indices": [i for i, _ in topk],
        "values": [v for _, v in topk]
    }

def upload_sparse_index():
    print("âœ… [SPARSE] ë²¡í„° ì¸ë±ì‹± ì‹œì‘")

    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))

    # âœ… ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ë§Œ (ìƒì„±ì€ ì›¹ ì½˜ì†”ì—ì„œ)
    if SPARSE_INDEX_NAME not in pc.list_indexes().names():
        print(f"âŒ ì¸ë±ìŠ¤ '{SPARSE_INDEX_NAME}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ Pinecone ì›¹ ì½˜ì†”ì—ì„œ Sparse ì¸ë±ìŠ¤ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        return

    texts, metadatas = load_texts_from_jsonl(DATA_PATH)
    encoder = BM25Encoder()
    encoder.fit(texts)  # âœ… fit ìˆ˜í–‰
    sparse_vectors = encoder.encode_documents(texts)
    sparse_vectors = [truncate_sparse_vector(vec) for vec in sparse_vectors]

    index = pc.Index(SPARSE_INDEX_NAME)
    to_upsert = []
    skipped = 0

    for i in range(len(texts)):
        vec = sparse_vectors[i]
        # âœ… ë¹ˆ ë²¡í„° ì™„ì „ ì œê±°
        if len(vec["indices"]) == 0 or len(vec["values"]) == 0:
            skipped += 1
            continue
        to_upsert.append(Vector(id=f"id-{i}", sparse_values=vec, metadata=metadatas[i]))

    print(f"ğŸ“Š ì—…ë¡œë“œí•  ë²¡í„°: {len(to_upsert)}ê°œ (ê±´ë„ˆë›´ ë²¡í„°: {skipped}ê°œ)")

    BATCH_SIZE = 300
    success_count = 0

    for i in range(0, len(to_upsert), BATCH_SIZE):
        batch = to_upsert[i:i+BATCH_SIZE]
        try:
            index.upsert(vectors=batch)
            success_count += len(batch)
            print(f"âœ… ë°°ì¹˜ {i//BATCH_SIZE + 1} ì™„ë£Œ ({len(batch)}ê°œ)")
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ {i//BATCH_SIZE + 1} ì‹¤íŒ¨: {e}")

    print(f"âœ… [SPARSE] ì´ {success_count}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ")