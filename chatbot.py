from transformers import pipeline
from query.query_pipeline import get_top_documents
from config import RERANKING_STRATEGY, TOP_K

llm_pipeline = pipeline("text2text-generation", model="google/flan-t5-small")

def get_final_answer(query: str) -> str:
    docs = get_top_documents(query)  # str ë¦¬ìŠ¤íŠ¸
    context = "\n\n".join(docs)[:1000]

    prompt = f"""
    ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

    [ë¬¸ì„œ]
    {context}

    [ì§ˆë¬¸]
    {query}

    [ë‹µë³€]
    """

    result = llm_pipeline(prompt, max_new_tokens=300, do_sample=False)
    print("ğŸ” Raw result:", result)
    return result[0]["generated_text"]
